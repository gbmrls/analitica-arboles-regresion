---
title: "Board_Games_Regression_Project"
author: 'Adrian Homero Moreno García- adrian.moreno@iteso.mx, Gabriel Alejandro Morales
  Ruiz- ie693871@iteso.mx'
date: "6/21/2021"
output:
  html_document:
    toc: yes
    df_print: paged
  github_document:
    toc: yes
    dev: jpeg
  html_notebook:
    toc: yes
    toc_float: yes
    theme: cosmo
    highlight: tango
---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(echo= TRUE,
                      fig.height = 6, fig.width = 7)
```

<style>
.forceBreak { -webkit-column-break-after: always; break-after: column; }
</style>

<center>
![](./images/iteso.jpeg){width=20%}


</center>

## Introducción

José es un diseñador de juegos de mesa. Crea las reglas, diseña los gráficos, escoge su tema, número de jugadores y duración promedio del juego que tiene en mente. José es una persona tímida, y a pesar de que sus juegos suelen gustarle a sus amigos, él nunca ha querido publicarlos por miedo a que no sean bien recibidos. Se quiere demostrar a José, con una base de datos de calificaciones históricas de juegos de mesa, cómo hubieran sido recibidos sus juegos en promedio en la época que los fue creando.

Los datos a utilizar vienen de esta base de datos: 
[(board_games)](https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-03-12)*
que, en cambio, vienen de la página Board Game Geek.

## Instalación de Paquetes

Procedemos para empezar en instalar los siguientes paquetes, se puede omitir este paso si ya se tienen previamente instalados. Aquí una lista de los cuales vamos a necesitar.

```{r}
#install.packages("data.table")
#install.packages("h2o")
#install.packages("ggplot2")
#install.packages("ggthemes")
#install.packages("data.tree")
#install.packages("tidyverse")
#install.packages("modeldata")
#install.packages("DataExplorer")
#install.packages("vtree")
#install.packages("caTools")
#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("lares")
```
## Cargar Librerías
 
Usando 'library' cargamos las librerías, con las cuales vas a hacer uso de las diferentes funciones. 

```{r}
library("data.table")
library("h2o")
library("ggplot2")
library("ggthemes")
library("data.tree")
library("tidyverse")
library("modeldata")
library("DataExplorer")
library("vtree")
library("caTools")
library("rpart")
library("rpart.plot")
library("lares")
```

## Ánalisis Descriptivo, Data Engineering
 
### Leemos nuestro dataset

En este caso usamos read.csv. Procedemos a leer:

```{r}
board_games <- read.csv("./board_games.csv") 
```

### Observación de las primeras líneas

- game_id	Identificador único
- description	Descripción corta
- image	URL con imagen del juego
- max_players	Jugadores máximos
- max_playtime	Tiempo máximo de juego
- min_age	Edad mínima
- min_players	Jugadores mínimos
- min_playtime	Tiempo mínimo de juego
- name	Nombre del juego
- playing_time	Tiempo promedio de juego
- thumbnail	URL con thumbnail del juego
- year_published	Año de publicación
- artist	Diseñador gráfico del juego
- category	Categorías del juego (separadas por coma)
- compilation	Si es parte de una compilación, nombre de la compilación
- designer	Diseñador del juego
- expansion	Si hay una expansión, el nombre de la expansión
- family	Familia, equivalente a editora
- mechanic	Mecánicas, separadas por coma
- publisher	Compañía o persona que publicaron el juego (separadas por coma)
- average_rating	Calificación promedio en Board Game Geek
- users_rated	Número de usuarios que calificaron el juego

```{r}
head(board_games)
```

### Colnames de nuestro dataset

Después de una rápida observación, ejecutamos los siguientes comandos para confirmación:

```{r}
colnames(board_games)
```

### Tipo de variables

Usando data explorer observamos el tipo de variables, casi tenemos el mismo porcentaje para las discretas y continua, y tenemos un bajo porcentaje de missing values:

- Sólo el 0.99% de las filas están completas,
- tenemos 11.54% de observaciones faltantes, es decir, dado que solo tenemos 0.99% de las filas completas, solo hay 10.55% de observaciones faltantes del total.

Estos valores faltantes nos podrán general problemas para analizar los datos, veamos un poco los perfiles que faltan.

```{r barplot}
plot_intro(board_games)
```

### Missing plot

Para visualizar el perfil de los datos faltantes podemos utilizar la función plot_missing(). En la visualización debajo, podemos ver que la variables compilation y expansion, son las que les falta información, encontramos de que sólo el 2.63% (compilation), 16.54% (expansion) de nuestras filas estén completas y probablemente esta varible no sea de mucha infomación. Por tanto la podemos eliminar de nuestro dataframe, ahorita mismo!!

```{r}
plot_missing(board_games)
```

### Eliminamos la columna que tiene más missing values

Eliminamos compilation y expansion de nuestro dataframe:

```{r}
final_board_games <- drop_columns(board_games, c("description", "image", "name", "thumbnail", "game_id", "compilation","expansion", "family", "artist", "mechanic"))
final_board_games <- drop_columns(final_board_games, c("designer", "publisher"))
colnames(final_board_games)
```


```{r}
final_board_games <- na.omit(final_board_games) 
```

### Ánalisis de Correlación

Podemos ver la más alta correlación en estas variables:

- min_playtime-max_playtime
- min_playtime-min_age
- min_playtime-playing_time
- average_rating-min_age

```{r}
plot_correlation(na.omit(final_board_games), maxcat = 5L)
```
Ahora de una manera más detallada vamos a analizar las variables más correlacionadas entre sí. El top 10:

```{r}
corr_cross(final_board_games, # name of dataset
  max_pvalue = 0.05, # display only significant correlations (at 5% level)
  top = 10 # display top 10 couples of variables (by correlation coefficient)
)
```
### QQ plot

La gráfica Quantile-Quantile es una forma de visualizar la desvisión de una distribución de probabilidad específica.

Después de analizar estos gráficos, a menudo es beneficioso aplicar una transformación matemática (como logaritmo) para modelos como la regresión lineal. Para hacerlo, podemos usar la función plot_qq. De forma predeterminada, se compara con la distribución normal.

```{r}
qq_data <- final_board_games[, c("min_playtime", "max_playtime", "min_age", "playing_time", "average_rating")]

plot_qq(qq_data, sampled_rows = 1000L)

```
En el gráfico, las columnas parecen sesgadas en ambas colas. Apliquemos una transformación logarítmica simple y grafiquemos de nuevo. 
```{r}
log_qq_data <- update_columns(qq_data, 1:5, function(x) log(x + 1))


plot_qq(log_qq_data, sampled_rows = 1000L)

```

### Ánalisis Exploratorio de los Datos
Teniendo nuestras variables con mayor correlación vamos a graficarlas con geom point..:

- min_playtime-min_age

```{r}
final_board_games %>%  ggplot(aes(x = min_playtime, y = min_age)) + 
  geom_point()
```

- average_rating-min_age


```{r}
final_board_games %>%  ggplot(aes(x = average_rating, y = min_age)) + 
  geom_point()
```

- average_rating-playing_time


```{r}
final_board_games %>%  ggplot(aes(x = playing_time, y = average_rating)) + 
  geom_point()
```

- users_rated-average_rating


```{r}
final_board_games %>%  ggplot(aes(x = users_rated, y = average_rating)) + 
  geom_point()
```


###Using vtree para explorar

Usamos vtree para observar la concentración de los datos por ejemplo para min_age, donde la mayoría de los datos se concentran en min_age de 8 años, 10 años y 12 años.

```{r}
vtree(final_board_games, "min_age")
```

Usamos vtree para observar la concentración de los datos por ejemplo para min_players, tenemos casi un 69% para min 2 jugadores y cerca del 19% para min 3 jugadores.

```{r}
vtree(final_board_games, "min_players")
```


Usamos vtree para observar la concentración de los datos por ejemplo para max_players, tenemos casi un 23% para máx 4 jugadores y cerca del 25% para máx 6 jugadores.

```{r}
vtree(final_board_games, "max_players")
```


### ¿Que se ha hecho hasta ahora?

Se realizó una exploración de datos, donde primero eliminalos columnas que no tienen mucha significancia en la predicción de nuestra variable de calificación. Después vimos su correlación entre las existentes.

Se tiene más claro cuales son las variables más significativas a la predicción, se hizo una limpieza, tenemos datos más contundentes con los cuales comenzar nuestra predicción, menos outliers sobre todo.


## Propuestas

Debido a que el problema intenta convencer a José de que sus juegos pudieron haber sido (en promedio) bien recibidos, y de cómo se espera que se reciban en un futuro, la variable de salida de nuestro problema es la calificación de los usuarios del sitio web. Esto puede hacerse de dos maneras: una regresión y tomar la calificación como una variable continua, o redondear y tomarlo como problema de clasificación (calificación discreta de 0 a 10). Las propuestas para estos casos son

### Regresión
- Support Vector Regression
- Random Forest
- Regresión lineal múltiple

### Clasificación
- Support Vector Machine
- Random Forest
- Multilayer perceptron

Vamos a suponer que a la comunidad de juegos de mesa no les importa tanto el historial del autor del juego ni quién lo publique, por lo que esas columnas se eliminarían del análisis.
Si José ve que sus juegos no hubieran gustado, al menos podrá tener un modelo con el cuál puede saber qué es lo que suele gustarle a la gente, por lo que podría hacer investigación de seguimiento para entablar las causas raíces.

# Modelado

Primero hacemos la separación de los datos en train y test. Todos los modelos usarán los mismos subconjuntos para poder evaluarlos y compararlos en un terreno nivelado.

```{r}
library(caTools)
set.seed(0)
split = sample.split(final_board_games, SplitRatio=0.6)
data.train = subset(final_board_games, split=TRUE)
data.test = subset(final_board_games, split=FALSE)
```


## Regresión

### Support Vector Regression

```{r}
library(caret)
library(doParallel)
set.seed(0)
control = trainControl(method="repeatedcv", repeats=5, search="random")
registerDoParallel(cores = parallel::detectCores() - 1)
model.svr = train(average_rating ~ ., data = drop_columns(data.train, "category"),
               method = "svmRadial",
               tuneLength = 15,
               metric = "RMSE",
               preProc = c("center", "scale"),
               trControl = control)
model.svr

```

```{r}
plot_qq(predict(model.svr, newdata=data.test) - data.test$average_rating)
```


### Random Forest

```{r}
library(h2o)
h2o.init()

data.h2o.train = as.h2o(data.train)
data.h2o.test = as.h2o(data.test)


model.h2o.rf = h2o.randomForest(
  training_frame = data.h2o.train,
  validation_frame = data.h2o.test,
  x = c(1, 2, 3, 4, 5, 6, 7, 8, 10),
  y = 9,
  model_id = "rf_covType_v1",
  ntrees = 200,
  stopping_rounds = 2,
  score_each_iteration = T,
  seed = 26
)

summary(model.h2o.rf)
```


## Clasificación

```{r}
library(tidymodels)

data.train.discrete = data.train %>% mutate(discrete_rating = round(average_rating)) %>% drop_columns("average_rating")
data.test.discrete = data.test %>% mutate(discrete_rating = round(average_rating)) %>% drop_columns("average_rating")

rf = rand_forest(
  mode = "classification",
  trees = tune(),
  min_n = tune()
) %>% set_engine(engine = "randomForest")

transformer = recipe(
  formula = discrete_rating ~ .,
  data = data.train.discrete
)

cv_folds = vfold_cv(
  data = data.train.discrete,
  v = 5,
  strata = discrete_rating
)

workflow_modelado = workflow() %>%
  add_recipe(transformer) %>%
  add_model(rf)

hp_grid = grid_regular(
  trees(range = c(50L, 3000L), trans = NULL),
  min_n(range = c(2L, 100L), trans = NULL),
  levels = 5
)

registerDoParallel(cores = parallel::detectCores() - 1)

grid_fit = tune_bayes(
  workflow_modelado,
  resamples = cv_folds,
  initial = 20,
  iter = 30,
  control = control_bayes(no_improve = 20, verbose = FALSE)
)
```


### Support Vector Machine

### Random Forest

